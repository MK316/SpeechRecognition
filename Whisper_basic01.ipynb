{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPx4K/Cj684D01Nyh8ziGpj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/SpeechRecognition/blob/main/Whisper_basic01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whisper Basics (OpenAI)\n",
        "+ 2025.07.11"
      ],
      "metadata": {
        "id": "zfSkvo5wNhxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Whisper and dependencies"
      ],
      "metadata": {
        "id": "95acZSTvNsJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBzKDxVALpkM"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install Whisper and dependencies\n",
        "!pip install -U openai-whisper\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import whisper\n",
        "## Step 3: Load the model"
      ],
      "metadata": {
        "id": "pRvVJTwgNu2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import whisper\n",
        "import whisper\n",
        "\n",
        "# Step 3: Load the model (use 'base', 'small', 'medium', or 'large')\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "cgQct5V4L1wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Audio file (upload or read)"
      ],
      "metadata": {
        "id": "O9BbxQC2OS97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Upload audio file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload an audio file (e.g., mp3, wav, m4a)"
      ],
      "metadata": {
        "id": "14X3c7iZOTct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Transcribe (function)\n",
        "## Step 6: Print result (transcribed text): Audio-to-Text"
      ],
      "metadata": {
        "id": "GNsC1L_QOA9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Transcribe\n",
        "import os\n",
        "filename = list(uploaded.keys())[0]  # get uploaded file name\n",
        "result = model.transcribe(filename)\n",
        "\n",
        "# Step 6: Print result\n",
        "print(\"*\"*50)\n",
        "print(\"ðŸ’™ Transcription:\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "6a7VIrYMMv3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read an audio file from colab (uploaded on the left)"
      ],
      "metadata": {
        "id": "x93fWbhlPLkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Change from) Step 4b: reading audio files differently"
      ],
      "metadata": {
        "id": "IIbQB5RyPUqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+[audio files to download](https://github.com/MK316/SpeechRecognition/blob/main/audio/sample1.wav)"
      ],
      "metadata": {
        "id": "sjSj8za5T4Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "filename = \"/content/sample2.mp3\"\n",
        "display(Audio(filename))"
      ],
      "metadata": {
        "id": "AYEZx-TDOwij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Transcribe\n",
        "import os\n",
        "# filename = list(uploaded.keys())[0]  # get uploaded file name\n",
        "result = model.transcribe(filename)\n",
        "\n",
        "# Step 6: Print result\n",
        "print(\"*\"*50)\n",
        "print(\"ðŸ’™ Transcription:\")\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "id": "c1nBsnIgPWlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}